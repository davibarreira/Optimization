{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook obtained from this [link](https://faculty.arts.ubc.ca/pschrimpf/526/julia/optimization.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interior Point Method\n",
    "\n",
    "Interior point methods circumvent the problem of figuring out which constraints bind by approaching the optimum from the interior of the feasible set. To do this, the interior point method applies Newton’s method to a modified version of the first order condition. The unmodified first order conditions can be written \\begin{align*} 0 = & Df_x - \\lambda^T Dc_x \\\\ 0 = & \\lambda_i c_i(x) \\\\ \\lambda \\geq & 0 \\\\ c(x) \\geq & 0 \\end{align*}\n",
    "A difficulty with these conditions is that solving them can require guessing and checking which combinations of constraints bind and which do not. Interior point methods get around this problem by beginning with an interior \\(x\\) and ($\\lambda$) such that $(\\lambda>0)$ and\n",
    "$(c(x)>0)$. They are then updated by applying Newton’s method to the equations\n",
    "\\begin{align*} 0 = & Df_x - \\lambda^T Dc_x \\\\ \\mu = & \\lambda_i c_i(x) \\\\ \\end{align*}\n",
    "where there is now a ($\\mu$) in place of (0) in the second equation. \\(x\\) and $(\\lambda)$ are updated according to Newton’s method for this\n",
    "system of equations.\n",
    "In particular, $(x_{new} = x + \\Delta_x)$ and $(\\lambda_{new}= \\lambda + \\Delta_\\lambda)$, \n",
    "where \n",
    "\\begin{align*} \\begin{pmatrix} - ( Df_x - \\lambda^T Dc_x) \\\\ \\mu 1_m - diag(c(x)) \\lambda \\end{pmatrix} = \\begin{pmatrix} D^2 f_x - D^2 (\\lambda c)_x & -Dc_x^T \\\\ \\lambda Dc_x & diag(c(x)) \\end{pmatrix} \\begin{pmatrix} \\Delta_x \\\\ \\Delta_\\lambda \\end{pmatrix} \\end{align*}\n",
    "\n",
    "Over iterations ($\\mu$) is gradually decreased toward \\(0\\). Here is one simple implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /home/davi/.julia/compiled/v1.0/Plots/ld3vC.ji for Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1190\n"
     ]
    }
   ],
   "source": [
    "using ForwardDiff\n",
    "using LinearAlgebra\n",
    "using Plots, Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "constraint (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    interiorpoint(f, x0, c; tol=1e-4, maxiter = 1000,\n",
    "                  μ0 = 1.0, μfactor = 0.2,\n",
    "                  xrange=[-2., 3.],\n",
    "                  yrange=[-2.,6.], animate=true)\n",
    "\n",
    "  Find the minimum of function `f` subject to `c(x) >= 0` using a\n",
    "  primal-dual interior point method.\n",
    "  \n",
    "  Inputs:\n",
    "  \n",
    "  - `f` function to minimizie\n",
    "  - `x0` starting value. Must have c(x0) > 0\n",
    "  - `c` constraint function. Must return an array.\n",
    "  - `tol` convergence tolerance\n",
    "  - `μ0` initial μ\n",
    "  - `μfactor` how much to decrease μ by\n",
    "  - `xrange` range of x-axis for animation\n",
    "  - `yrange` range of y-axis for animation\n",
    "  - `animate` whether to create an animation (if true requires length(x)==2)\n",
    "  - `verbosity` higher values result in more printed output during search. 0 for no output, any number > 0 for some.  \n",
    "  \n",
    "  Output:\n",
    "\n",
    "  - `(fmin, xmin, iter, info, animate)` tuple consisting of minimal function\n",
    "    value, minimizer, number of iterations, and convergence info\n",
    "\n",
    "\"\"\"\n",
    "function interiorpoint(f, x0, c; tol=1e-4, maxiter = 1000,\n",
    "                       μ0 = 1.0, μfactor = 0.2,\n",
    "                       xrange=[-2., 3.],\n",
    "                       yrange=[-2.,6.], animate=true, verbosity=0)\n",
    "  fold = f(x0)\n",
    "  xold = x0\n",
    "  all(c(x0).>0) || error(\"interiorpoint requires a starting value that strictly satisfies all constraints\")\n",
    "  μ = μ0\n",
    "  λ = μ./c(x0)\n",
    "  xchange=Inf\n",
    "  fchange=Inf\n",
    "  iter = 0\n",
    "  μiter = 0\n",
    "  stuck=0\n",
    "\n",
    "  animate = animate && length(x0)==2\n",
    "  if animate\n",
    "    # make a contour plot of the function we're minimizing. This is for\n",
    "    # illustrating; you wouldn't have this normally\n",
    "    ct = contour(range(xrange[1],stop=xrange[2], length=100), \n",
    "                range(yrange[1],stop=yrange[2], length=100),\n",
    "                 (x,y) -> log(f([x,y])))\n",
    "    plot!(ct, xrange, 2.5 .- xrange) # add constraint \n",
    "    anim = Animation()\n",
    "  end\n",
    "  L(x,λ) = f(x) - λ'*c(x)\n",
    "  foc = [ForwardDiff.gradient(x->L(x,λ),xold); λ.*c(xold)]\n",
    "  while(iter < maxiter && ((xchange>tol) || (fchange>tol) || (stuck>0)\n",
    "                           || norm(foc)>tol || μ>tol) )\n",
    "    # Calculate the direction for updating x and λ\n",
    "    Dc = ForwardDiff.jacobian(c, xold)\n",
    "    cx = c(xold)\n",
    "    foc = ForwardDiff.gradient(x->L(x,λ),xold)\n",
    "    H = ForwardDiff.hessian(x->L(x,λ),xold)\n",
    "#     Δ = [H   -Dc'; λ'*Dc  diagm(cx)] \\ [-foc; μ .- cx.*λ]\n",
    "    Δ = [H   -Dc'; λ'*Dc  cx] \\ [-foc; μ .- cx.*λ]\n",
    "\n",
    "    # Find a step size such that λ>=0 and c(x)>=0\n",
    "    # The details here could surely be improved\n",
    "    α = 1.0\n",
    "    acceptedstep = false\n",
    "    λold = copy(λ)\n",
    "    x = copy(xold)\n",
    "    while (α > 1e-10)\n",
    "      x = xold + α*Δ[1:length(xold)]\n",
    "      λ = λold + α*Δ[(length(xold)+1):length(Δ)]\n",
    "      if (all(λ.>=0) && all(c(x).>=0))\n",
    "        acceptedstep=true\n",
    "        break\n",
    "      end\n",
    "      α *= 0.5\n",
    "    end\n",
    "    if !acceptedstep\n",
    "      stuck = 1\n",
    "      break\n",
    "    end\n",
    "    fnew = f(x)\n",
    "\n",
    "    if (animate)\n",
    "      scatter!(ct, [xold[1]],[xold[2]], markercolor=:red, legend=false,\n",
    "               xlims=xrange, ylims=yrange) \n",
    "      quiver!(ct, [xold[1]],[xold[2]], quiver=([α*Δ[1]],[α*Δ[2]]), legend=false,\n",
    "              xlims=xrange, ylims=yrange)\n",
    "      frame(anim)\n",
    "    end\n",
    "\n",
    "    xchange = norm(x-xold)\n",
    "    fchange = abs(fnew-fold)\n",
    "    μiter += 1\n",
    "\n",
    "    # update μ (the details here could also be improved)    \n",
    "    foc = ForwardDiff.gradient(x->L(x,λ),x)\n",
    "    if (μiter>10 || (norm(foc)< μ && λ'*c(x)<10*μ)) \n",
    "      μ *=  μfactor\n",
    "      μiter = 0\n",
    "    end\n",
    "    \n",
    "    xold = x\n",
    "    fold = fnew\n",
    "    if verbosity>0\n",
    "      print(\"Iter $iter: f=$fnew, λ=$λ, c(x)=$(c(x)), μ=$μ, norm(foc)=$(norm(foc))\\n\")\n",
    "    end\n",
    "    iter += 1    \n",
    "  end\n",
    "  if (iter >= maxiter)\n",
    "    info = \"Maximum iterations reached\"\n",
    "  elseif (stuck>0)\n",
    "    info = \"Failed to find feasible step for \" * string(stuck) * \" iterations.\"\n",
    "  else\n",
    "    info = \"Convergence.\"\n",
    "  end\n",
    "  return(fold, xold, iter, info, anim) \n",
    "end\n",
    "\n",
    "\"\"\"\n",
    "     banana(a,b)\n",
    "  \n",
    "  Returns the Rosenbrock function with parameters a, b.\n",
    "\"\"\"\n",
    "function banana(a,b)\n",
    "  x->(a-x[1])^2+b*(x[2]-x[1]^2)^2\n",
    "end\n",
    "f = banana(1.0,1.0)\n",
    "\n",
    "x0 = [3.0, 0.0]\n",
    "\n",
    "function constraint(x)\n",
    "  [x[1] + x[2] - 2.5]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0229613538312622, [1.14498, 1.35505], 16, \"Convergence.\", Animation(\"/tmp/tmpYsIaib\", [\"000001.png\", \"000002.png\", \"000003.png\", \"000004.png\", \"000005.png\", \"000006.png\", \"000007.png\", \"000008.png\", \"000009.png\", \"000010.png\", \"000011.png\", \"000012.png\", \"000013.png\", \"000014.png\", \"000015.png\", \"000016.png\"]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = interiorpoint(f, x0, constraint; maxiter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved animation to \n",
      "│   fn = /home/davi/Dropbox/FGV/EMAp/Optimization/ip.gif\n",
      "└ @ Plots /home/davi/.julia/packages/Plots/Iuc9S/src/animation.jl:95\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"ip.gif\" />"
      ],
      "text/plain": [
       "Plots.AnimatedGif(\"/home/davi/Dropbox/FGV/EMAp/Optimization/ip.gif\")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gif(result[5], \"ip.gif\", fps=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
